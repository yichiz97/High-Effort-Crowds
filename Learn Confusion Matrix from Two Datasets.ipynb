{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. World 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first dataset is downloaded from \n",
    "\"https://www.sciencedirect.com/science/article/pii/S1093326317306575#ec-research-data\" (effected by May 2022).\n",
    "World $1$ has a signal space of size $5$ and a binary ground truth, say $\\{1,2\\}$.  Agents are asked to grade the synthetic accessibility of compounds with scores $1$ to $5$, where $1$ indicates inappropriate to be synthesized and $5$ stands for appropriate. Scores in between lower the confidence of the grading. The binary ground truth indicates whether a compound is appropriate or inappropriate. The dataset includes the assessments of $100$ compounds (tasks) from $18$ agents, among which we only use the $62$ tasks that have the ground truth and the $5$ agents who are the experts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth prior: w = [0.61290323 0.38709677]\n"
     ]
    }
   ],
   "source": [
    "# Read the question dataset and learn the ground truth mapping, as well as the prior of the ground truth\n",
    "file_q = open('Data/W1_crowd-synthetic-accessibility-dataset/questions.csv', \"r\")\n",
    "csv_reader = csv.reader(file_q)\n",
    "ground_truth = {}\n",
    "for row in csv_reader:\n",
    "    if row[0] != 'problem_id':\n",
    "        if row[2] == 'inappropriate':\n",
    "            ground_truth[row[0]] = 1\n",
    "        elif row[2] == 'appropriate':\n",
    "            ground_truth[row[0]] = 2\n",
    "\n",
    "n1 = np.count_nonzero(np.array(list(ground_truth.values())) == 1)\n",
    "n2 = np.count_nonzero(np.array(list(ground_truth.values())) == 2)\n",
    "w = np.array([n1,n2])/(n1+n2)\n",
    "print('Ground truth prior: w =', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: Gamma =\n",
      "[[0.68421053 0.22105263 0.03157895 0.03684211 0.02631579]\n",
      " [0.09166667 0.19166667 0.05       0.2        0.46666667]]\n"
     ]
    }
   ],
   "source": [
    "# Read the response dataset and collect the response from the experts and learn the confusion matrix\n",
    "file_r = open('Data/W1_crowd-synthetic-accessibility-dataset/response.csv', \"r\")\n",
    "csv_reader = csv.reader(file_r)\n",
    "count = np.zeros((2,5))\n",
    "Gamma = np.zeros((2,5))\n",
    "for row in csv_reader:\n",
    "    if row[0][0] == 'E' and row[1] in ground_truth.keys(): # if the task is graded by the expert and has ground truth\n",
    "        count[ground_truth[row[1]]-1, int(row[4])-1] += 1\n",
    "for i in range(2):\n",
    "    Gamma[i] = count[i]/np.sum(count[i])\n",
    "print('Confusion matrix: Gamma =')\n",
    "print(Gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. World 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "World $2$ has an identical signal space and ground truth space of size $4$ (actually the size is $5$, but we ignore the rarest one which occurs $9$ out of $300$ times). The dataset contains $6000$ classifications of the sentiment of $300$ tweets (tasks) provided by $110$ workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "csv_url = 'https://eprints.soton.ac.uk/376543/1/WeatherSentiment_amt.csv'\n",
    "\n",
    "req = requests.get(csv_url)\n",
    "url_content = req.content\n",
    "csv_file = open('Data/W2_weather_sentiment.csv', 'wb')\n",
    "csv_file.write(url_content)\n",
    "csv_file.close()\n",
    "\n",
    "# Read the dataset\n",
    "file = open('Data/W2_weather_sentiment.csv', \"r\")\n",
    "csv_reader = csv.reader(file)\n",
    "lists_from_csv = []\n",
    "for row in csv_reader:\n",
    "    lists_from_csv.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of the reports\n",
    "n = 110\n",
    "m = 300\n",
    "\n",
    "Workers = [] # names of workers\n",
    "Tasks = [] # names of tasks\n",
    "R = np.zeros((n,m))\n",
    "count = np.zeros((n,m))\n",
    "Y = np.zeros(m)\n",
    "for data in lists_from_csv:\n",
    "    if data[0] not in Workers:\n",
    "        Workers.append(data[0])\n",
    "    if data[1] not in Tasks:\n",
    "        Tasks.append(data[1])\n",
    "    i = Workers.index(data[0])\n",
    "    j = Tasks.index(data[1])\n",
    "    R[i,j] = int(data[2])+1\n",
    "    Y[j] = int(data[3])+1\n",
    "    count[i,j] = int(data[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth prior: w = [0.19587629 0.24054983 0.24742268 0.3161512 ]\n",
      "Confusion matrix: Gamma =\n",
      "[[0.77056673 0.12157221 0.08409506 0.023766  ]\n",
      " [0.09083969 0.7351145  0.12977099 0.04427481]\n",
      " [0.03326256 0.06157113 0.86624204 0.03892427]\n",
      " [0.06785509 0.16388729 0.09890742 0.6693502 ]]\n"
     ]
    }
   ],
   "source": [
    "# ignore the minority case\n",
    "R[np.where(R==5)] = 0\n",
    "Y[np.where(Y==5)] = 0\n",
    "\n",
    "w = np.zeros(4)\n",
    "Gamma = np.zeros((4,4))\n",
    "\n",
    "for s in range(4):\n",
    "    w[s] = np.count_nonzero(Y == s+1)/np.count_nonzero(Y != 0)\n",
    "\n",
    "for s in range(4):\n",
    "    for d in range(4):\n",
    "        Gamma[s,d] = np.count_nonzero(R[:,np.where(Y == s+1)] == d+1)/np.count_nonzero(R[:,np.where(Y == s+1)] != 0)\n",
    "        \n",
    "print('Ground truth prior: w =', w)\n",
    "print('Confusion matrix: Gamma =')\n",
    "print(Gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
