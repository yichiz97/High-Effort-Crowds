{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choices\n",
    "from random import sample\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Crowdsourcing Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part, we first define the parameters that will be used in our crowdsourcing model. Then, we simulate the reports for for all agents based on the crowdsourcing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the crowdsourcing model and generate agents' reports.\n",
    "\"\"\"\n",
    "\n",
    "class Crowdsourcing:\n",
    "    def __init__(self, w, Gamma_w, Gamma_s, \n",
    "                       m = 1000, \n",
    "                       n0 = 5, \n",
    "                       mi = 100, \n",
    "                       signal = [1,2,3,4,5]):\n",
    "        self.m = m # Total number of tasks\n",
    "        self.n0 = n0 # Minimum number of agents that are assigned to each task\n",
    "        self.mi = mi # Number of tasks that each agent answers\n",
    "        self.signal = signal # Signal space\n",
    "        self.K = len(signal)\n",
    "        self.w = w # Prior of ground truth\n",
    "        self.Gamma_w = Gamma_w # Confusion matrix of full effort worker\n",
    "        self.Gamma_s = Gamma_s # Confusion matrix of zero effort shirker\n",
    "        \n",
    "        \n",
    "def Report_Generator(para, E, n_E):\n",
    "    \"\"\"\n",
    "    Input: \"para\" is a class variable of Crowdsouring that scores the parameters;\n",
    "           \"E\" is an array of effort which stores the types of effort level within the crowds;\n",
    "           \"n_E\" is an array of integers which stores the number of agents of each of the effort levels in \"E\".\n",
    "            \n",
    "    Output: \"X\" is the n*m matrix of all agents' reports;\n",
    "            \"Y\" is the ground truth of all tasks;\n",
    "            \"agent_e\" is the effort level of all agents, which is scored as the index corresponds in the vector E\n",
    "    \"\"\"\n",
    "            \n",
    "    m = para.m\n",
    "    n0 = para.n0\n",
    "    mi = para.mi\n",
    "    w = para.w\n",
    "    Gamma_w = para.Gamma_w\n",
    "    Gamma_s = para.Gamma_s\n",
    "    signal = para.signal\n",
    "    n = np.sum(n_E)\n",
    "    \n",
    "    agent_e = np.zeros(n) # Store the effort level of all agents. For example, agent_e[i] = j means the effort level of agent i is E[j].\n",
    "    for i in range(len(n_E)-1):\n",
    "        agent_e[np.sum(np.array(n_E)[0:i+1]):np.sum(np.array(n_E)[0:i+2])] = i+1\n",
    "        \n",
    "    Y = choices(list(range(1, len(w)+1)), w, k = m) # Randomly sample the ground truth of all tasks given prior w.\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop each of the tasks and randomly assign n0 agents. If at the end this assignment does not work, redo everything.\n",
    "    \"\"\"\n",
    "    flag = 0 # Mark the number of tasks that are assigned with at least n0 agents.\n",
    "    while flag < m: # until all the tasks have been marked as finished.\n",
    "        flag = 0\n",
    "        current_task = np.zeros(n) # Dynamically store the number of tasks each agent has answered in the current round.\n",
    "        X = np.zeros((n, m))\n",
    "        for j, y in enumerate(Y):\n",
    "            if np.count_nonzero(current_task < mi) < n0: # If the number of remaining agents who can still work is less than the minimum required number n0, then the current assignment does not work, rerun everything.\n",
    "                break\n",
    "            else:\n",
    "                flag += 1 # there are enough agents to work, then one more task is finished.\n",
    "            random_agents = np.array(sample(list(np.where(current_task < mi)[0]), n0)) # randomly select the agents who will work on the current task.\n",
    "            for i in random_agents:\n",
    "                e = E[int(agent_e[i])]\n",
    "                Gamma_i = e*Gamma_w + (1-e)*Gamma_s\n",
    "                X[i,j] = choices(signal, Gamma_i[Y[j]-1])[0]\n",
    "            current_task[random_agents] += 1 # mark that the sellected agents have used one more of their mi budget.\n",
    "    \n",
    "    \"\"\"\n",
    "    For those agents who worked on less than mi tasks, randomly assign them some tasks to work.\n",
    "    \"\"\"\n",
    "    extra_agents = np.where(np.count_nonzero(X, axis = 1) < mi)[0]\n",
    "    for i in extra_agents:\n",
    "        e = E[int(agent_e[i])]\n",
    "        Gamma_i = e*Gamma_w + (1-e)*Gamma_s\n",
    "        more_tasks = sample(list(np.where(X[i] == 0)[0]), mi - np.count_nonzero(X[i])) # find more tasks that has not been answered by agent i.\n",
    "        for j in more_tasks:\n",
    "            X[i,j] = choices(signal, Gamma_i[Y[j]-1])[0]\n",
    "    \n",
    "    return (X, Y, agent_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Performance Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part contains the implementations of all the spot-checking and peer prediction mechanisms that will be discussed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Spot-checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 The accuracy based spot-checking mechanism (SC-Acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mechanism scores each agent their accuracy on the spot-checked tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check_greedy(X, check_p):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"check_p\" is the spot-checking probability.\n",
    "    Output: \"check\" is the index of tasks that are checked.\n",
    "    ------------------\n",
    "    The algorithm selects the spot-checking tasks based on the number of disagreed answers.\n",
    "    \"\"\"\n",
    "    m = np.size(X, axis = 1)\n",
    "    disagree = np.zeros(m)\n",
    "    for i in range(m):\n",
    "        index = np.where(X[:,i] != 0)[0]\n",
    "        maj = mode(X[index,i])[0]\n",
    "        disagree[i] = np.count_nonzero(X[index,i] != maj)\n",
    "    m_check = int(m*check_p)\n",
    "    check = np.argsort(disagree)[-m_check:]\n",
    "    return check\n",
    "\n",
    "def spot_check_random(X, check_p):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"check_p\" is the spot-checking probability.\n",
    "    Output: \"check\" is the index of tasks that are checked.\n",
    "    ------------------\n",
    "    The algorithm randomly selects the spot-checking tasks.\n",
    "    \"\"\"\n",
    "    m = np.size(X, axis = 1)\n",
    "    m_check = int(m*check_p)\n",
    "    check = np.array(random.sample(list(range(m)),m_check))\n",
    "    return check\n",
    "\n",
    "\n",
    "def Spot_check_mechanism_acc_w1(X, Y_gt):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"Y_gt\" stores the ground truth of the spot-checked tasks. Unchecked tasks have values of zero.\n",
    "    Output: \"S\" is the score of all agents.\n",
    "    ------------------\n",
    "    This mechanism is designed for W1 where the ground truth space is 2 and the signal space is 5.\n",
    "    Agents' reports are projected down to the binary space.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    m = np.size(X, axis = 1)\n",
    "    Y_gt = np.array(Y_gt)\n",
    "    index_Y = np.where(Y_gt != 0)[0]\n",
    "    S = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        X_projected = np.zeros(m)\n",
    "        X_projected[X[i] == 1] = 1\n",
    "        X_projected[X[i] == 2] = 1\n",
    "        X_projected[X[i] == 4] = 2\n",
    "        X_projected[X[i] == 5] = 2\n",
    "        index_i = np.where(X_projected != 0)[0] # tasks ansewred by i\n",
    "        index = np.intersect1d(index_i, index_Y) # tasks answered by i and checked\n",
    "        S[i] = np.count_nonzero(X_projected[index] == Y_gt[index])/len(index)\n",
    "    return S\n",
    "\n",
    "\n",
    "\n",
    "def Spot_check_mechanism_acc_w2(X, Y_gt):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"Y_gt\" stores the ground truth of the spot-checked tasks. Unchecked tasks have values of zero.\n",
    "    Output: \"S\" is the score of all agents.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    m = np.size(X, axis = 1)\n",
    "    Y_gt = np.array(Y_gt)\n",
    "    index_Y = np.where(Y_gt != 0)[0]\n",
    "    S = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        index_i = np.where(X[i] != 0)[0]\n",
    "        index = np.intersect1d(index_i, index_Y)\n",
    "        S[i] = np.count_nonzero(X[i][index] == Y_gt[index])/len(index)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 The Dasgupta-Ghosh spot-checking mechanism (SC-DG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an agent's reports and a set of spot-checking questions with the ground truth, SC-DG randomly chooses a common task (bonus task) and two distinct tasks (penalty tasks). Then, the agent is scored $1$ if her report on the bonus task agrees with the ground truth, and scored $-1$ if agreeing on the penalty tasks. The final score of the agent is the average score after repeated sampling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Spot_check_mechanism_DG_w1(X, Y_gt):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"Y_gt\" stores the ground truth of the spot-checked tasks. Unchecked tasks have values of zero.\n",
    "    Output: \"S\" is the score of all agents.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    m = np.size(X, axis = 1)\n",
    "    Y_gt = np.array(Y_gt)\n",
    "    T = np.size(np.where(Y_gt != 0)[0])*5 # number of repeated rounds\n",
    "    index_Y = np.where(Y_gt != 0)[0]\n",
    "    S = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        X_projected = np.zeros(m)\n",
    "        X_projected[X[i] == 1] = 1\n",
    "        X_projected[X[i] == 2] = 1\n",
    "        X_projected[X[i] == 4] = 2\n",
    "        X_projected[X[i] == 5] = 2\n",
    "        index_i = np.where(X_projected != 0)[0] # tasks ansewred by i\n",
    "        index = np.intersect1d(index_i, index_Y) # tasks answered by i and checked\n",
    "        for j in range(T):\n",
    "            \n",
    "            # sample bonus and penalty tasks\n",
    "            b = sample(list(index), 1)[0]\n",
    "            p = sample(list(index_i), 1)[0]\n",
    "            while p == b:\n",
    "                p = sample(list(index_i),1)[0]\n",
    "            q = sample(list(index_Y), 1)[0]\n",
    "            while q == b or q == p:\n",
    "                q = sample(list(index_Y), 1)[0]\n",
    "                \n",
    "            if X_projected[b] == Y_gt[b]:\n",
    "                S[i] += 1\n",
    "            if X_projected[p] == Y_gt[q]:\n",
    "                S[i] -= 1\n",
    "    return S/T\n",
    "\n",
    "\n",
    "\n",
    "def Spot_check_mechanism_DG_w2(X, Y_gt):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"Y_gt\" stores the ground truth of the spot-checked tasks. Unchecked tasks have values of zero.\n",
    "    Output: \"S\" is the score of all agents.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    m = np.size(X, axis = 1)\n",
    "    Y_gt = np.array(Y_gt)\n",
    "    T = np.size(np.where(Y_gt != 0)[0])*5\n",
    "    index_Y = np.where(Y_gt != 0)[0]\n",
    "    S = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        index_i = np.where(X[i] != 0)[0]\n",
    "        index = np.intersect1d(index_i, index_Y)\n",
    "        for j in range(T):\n",
    "            b = sample(list(index), 1)[0]\n",
    "            p = sample(list(index_i), 1)[0]\n",
    "            while p == b:\n",
    "                p = sample(list(index_i),1)[0]\n",
    "            q = sample(list(index_Y), 1)[0]\n",
    "            while q == b or q == p:\n",
    "                q = sample(list(index_Y), 1)[0]\n",
    "            if X[i][b] == Y_gt[b]:\n",
    "                S[i] += 1\n",
    "            if X[i][p] == Y_gt[q]:\n",
    "                S[i] -= 1\n",
    "    return S/T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Peer Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 The output agreement mechanism (OA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OA pays an agent $1$ if her report on a random task agrees with a random peer's report on the same task, and paying $0$ otherwise. The score is then the averaged value while taking average over all the peers and tasks. To speed up the mechanism, instead of pairing agent $i$ with each of her peer $j$, we simply learn the empirical distributions of the reports on each task of all agents but $i$. This can be seen as a \"virtual agent\" reporting based on the empirical distributions of all agents but $i$. Then, agent $i$ is paired with only one agent: the virtual agent.\n",
    "\n",
    "We note that we use the trick of virtual agent in all of the peer prediction mechanisms that we implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mechanism_OA_individual(X, para, i):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "           \"i\" is the index of a particular agent.\n",
    "    Output: \"S\" is the score of agent i computed with the OA mechanism.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    X = np.array(X)\n",
    "    X_ni = np.vstack((X[0:i], X[i+1:n])) # all agents' reports but i.\n",
    "    pv = soft_predictor_learner(X_ni, para) # report distribution of the virtual agent (the empirical report distribution of all agents but i)\n",
    "    index_i = np.where(X[i] != 0)[0]\n",
    "    S = 0\n",
    "    for j in index_i:\n",
    "        S += pv[j,int(X[i,j])-1]/len(index_i)\n",
    "    return S\n",
    "\n",
    "def soft_predictor_learner(X, para):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is a matrix of agents' reports with each row the reports of each agent and each column the reports on each task.\n",
    "           \"para\" contains the crowdsourcing parameters.\n",
    "    Output: \"P\" is a m*K matrix where each row is the empirical distribution of agents' reports in X on each task.\n",
    "    \"\"\"\n",
    "    K = para.K\n",
    "    X = np.array(X)\n",
    "    m = np.size(X, axis = 1)\n",
    "    P = []\n",
    "    for j in range(m):\n",
    "        pj =  np.zeros(K)\n",
    "        nj = np.count_nonzero(X[:,j])\n",
    "        if nj != 0:\n",
    "            for i in range(K):\n",
    "                pj[i] = np.count_nonzero(X[:,j] == i+1)/nj # compute the empirical distribution of task j\n",
    "        P.append(pj)\n",
    "    return np.array(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 The Peer Truth Serum (PTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between PTS and OA is that in PTS, the payment if two agents agree on a task is proportional to $\\frac{1}{R(x)}$, where $R$ is a public distribution of reports and $x$ is the common report. We implement PTS by setting $R$ to be the empirical distribution of all the other agents' reports other than $i$ while computing agent $i$'s payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mechanism_PTS_individual(X, para, i):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "           \"i\" is the index of a particular agent.\n",
    "    Output: \"S\" is the score of agent i computed with the PTS mechanism.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    K = para.K\n",
    "    X = np.array(X)\n",
    "    X_ni = np.vstack((X[0:i], X[i+1:n]))\n",
    "    pv = soft_predictor_learner(X_ni, para) # report distribution of the virtual agent (the empirical report distribution of all agents but i)\n",
    "    index_i = np.where(X[i] != 0)[0]\n",
    "    counts = np.bincount(X_ni.astype(int).reshape(-1), minlength = K+1)\n",
    "    sig_prior = counts[1:]/np.sum(counts[1:]) # This is R, the empirical report distribution of all agents but i\n",
    "    S = 0\n",
    "    for j in index_i:\n",
    "        S += pv[j,int(X[i,j])-1]/(sig_prior[int(X[i,j])-1]*len(index_i))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 The $f$-matrix mutual information mechanism (f-MMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$-\\textbf{MMI} scores each agent using the estimation of the $f$-mutual information between her reports and her peer's report, where $f$ can be any convex function. \n",
    "\n",
    "With attention to detail, the $f$-MMI uses the empirical distributions to estimate the mutual information. \n",
    "We can simply estimate the empirical distributions between two agents' reports, i.e.~$\\widetilde{P}_{\\hat{X}_i, \\hat{X}_j}$ for joint distribution and $\\widetilde{P}_{\\hat{X}_i}$ for marginal distribution. Then, the MI between reports $\\hat{X}_i$ and $\\hat{X}_j$ can be estimated, \n",
    "\\begin{equation}\\label{eq:estimated_MI_matrix}\n",
    "    \\widetilde{MI}^{f-MMI}_{i,j} = \\sum_{x,y}\\widetilde{P}_{\\hat{X}_i, \\hat{X}_j}(x, y)f\\left(\\frac{\\widetilde{P}_{\\hat{X}_i}(x)\\widetilde{P}_{\\hat{X}_j}(y)}{\\widetilde{P}_{\\hat{X}_i, \\hat{X}_j}(x, y)}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "The matrix mutual information mechanism then scores each agent $i$ the average of the estimated MI between $i$ and each of her peer. To speed up the mechanism, we again use the \"virtual agent\" trick. Then, we learn the joint distribution as well as the mutual information between agent $i$'s reports and this virtual agent's reports.\n",
    "\n",
    "We implement the following four types of $f$ functions.\n",
    "\n",
    "   1) Total variation distance (TVD): $\\frac{1}{2}|a-1|$ \n",
    "   \n",
    "   2) KL-divergence (KL):   $a\\log a$  \n",
    "   \n",
    "   3) Pearson $\\chi^2$ (Sqr):   $(a-1)^2$ \n",
    "   \n",
    "   4) Squared Hellinger (Hlg):   $\\left(1-\\sqrt{a}\\right)^2$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mechanism_MMI_individual(X, f, para, i):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"f\" is the index of the convex function for the f-MMI mechanism, f = 0, 1, 2, 3 corresponds to the four f functions that we implement;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "           \"i\" is the index of a particular agent.\n",
    "    Output: \"S\" is the score of agent i computed with the f-MMI mechanism.\n",
    "    \"\"\"\n",
    "    m = para.m\n",
    "    n = np.size(X, axis = 0)\n",
    "\n",
    "    X_ni = np.vstack((X[0:i], X[i+1:n]))\n",
    "    pv = soft_predictor_learner(X_ni, para) # report distribution of the virtual agent (the empirical report distribution of all agents but i)\n",
    "    Qv = np.sum(pv, axis = 0)/m # Marginal distribution of the \"virtual agent\".\n",
    "    P, Qi = distribution_learner(X[i], pv, para) # P is the joint distribution, Q_i is the marginal distribution of agents i.\n",
    "    S = MI_computer_MMI(P, Qi, Qv, f)\n",
    "    return S\n",
    "\n",
    "def distribution_learner(Xi, Xv, para): \n",
    "    \"\"\"\n",
    "    Input: \"Xi\" is the reports of an agent i;\n",
    "           \"Xv\" is the report of the \"virtual agent\", i.e.~a probability distribution of reports on each task;\n",
    "           \"para\" contains the crowdsourcing parameters.\n",
    "    Output: \"P\" is the estimated joint distribution between agent i and the virtual agent's reports;\n",
    "            \"Qi\" is the empirical marginal distribution of agent i's reports.\n",
    "    \"\"\"\n",
    "    K = para.K\n",
    "    index_i = np.where(Xi != 0)[0]\n",
    "    P = np.zeros((K,K))\n",
    "    for j in index_i:\n",
    "        P[int(Xi[j])-1]+=Xv[j]/len(index_i)\n",
    "    Qi = np.zeros(K)\n",
    "    for j in range(K):\n",
    "        Qi[j] = np.count_nonzero(Xi == j+1)/len(index_i)\n",
    "    return P, Qi\n",
    "\n",
    "\n",
    "def MI_computer_MMI(P, Q1, Q2, f):\n",
    "    \"\"\"\n",
    "    Input: \"P\" is the joint distribution (matrix of size K*K);\n",
    "           \"Q1\" is the marginal distribution of the row agent (vector of length K);\n",
    "           \"Q2\" is the marginal distribution of the column agent (vector of length K);\n",
    "           \"f\" is a convex function\n",
    "    Output: \"MI\" is the estimated mutual information\n",
    "    \"\"\"\n",
    "    Q = Q2*Q1.reshape(-1, 1) # Product of the marginal sitributions (size of K*K)\n",
    "    \n",
    "    if f == 0: # TVD\n",
    "        MI = np.sum(np.absolute(P - Q))\n",
    "    elif f == 1: # KL\n",
    "        t = P*np.log(P/Q)\n",
    "        nan_ind = np.isnan(t)\n",
    "        t[nan_ind] = 0 \n",
    "        MI = np.sum(t)\n",
    "    elif f == 2: # Sqr\n",
    "        t = P*(np.square((Q/P)-1))\n",
    "        nan_ind = np.isnan(t)\n",
    "        t[nan_ind] = 0 \n",
    "        MI = np.sum(t)\n",
    "    elif f == 3: # Hlg\n",
    "        t = P*(np.square(np.sqrt(Q/P)-1))\n",
    "        nan_ind = np.isnan(t)\n",
    "        t[nan_ind] = 0 \n",
    "        MI = np.sum(t)\n",
    "    \n",
    "    return MI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 The $f$-pairing mutual information mechanism (f-PMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the main idea is to estimate the mutual information between agents' reports. Difference from MMI, PMI applies a different way to estimate the mutual information. Note that mutual information is a function of the quotient of the joint distribution and the product of the marginal distributions. We name this ratio as the \"joint to marginal product ratio\", denoted as JP.\n",
    "Then, JP can be further rewritten as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\frac{P_{\\hat{X}_i, \\hat{X}_{-i}}(\\hat{x}_i, \\hat{x}_{-i})}{P_{\\hat{X}_i}(\\hat{x}_i)P_{\\hat{X}_{-i}}(\\hat{x}_{-i})}=\\frac{P_{\\hat{X}_i| \\hat{X}_{-i}}(\\hat{x}_i| \\hat{x}_{-i})}{P_{\\hat{X}_i}(\\hat{x}_i)}.\n",
    "\\end{align}\n",
    "\n",
    "The denominator can be empirically estimated. While the numerator is a soft-predictor, which, given the reports of all agents except $i$ on a particular task $j$, produces a forecast of agent $i$'s report on the same task in the form of a distribution. In our experiments, we set the soft-predictor for agent $i$'s report on task $j$ as the empirical distribution of all the other agents' reports on the same task. \n",
    "\n",
    "The mechanism randomly and equally divide the set of tasks into two subsets, and use one subset to learn JP and the other to evaluate and pay agents. Specifically, say JP is learned with set A. Then, the mechainsm randomly chooses a common task (bonus task, b) and two distinct tasks (penalty tasks, p and q) from set B. Each agent will then be rewarded based on the following formula: (The selection of bonus and penalty tasks is repeated for $T$ times and taking average.)\n",
    "\\begin{align}\n",
    "    S_i = \\sum_{\\sigma\\in\\Sigma}p_{v,b}(\\sigma)K(\\hat{x}_{i,b}, \\sigma) - \\sum_{\\sigma\\in\\Sigma}p_{v,q}(\\sigma)f^*(K(\\hat{x}_{i,p}, \\sigma)),\n",
    "\\end{align}\n",
    "\n",
    "where $p_v$ is the report distribution of the \"virtual agent\" which is a $m*K$ matrix, then $p_{v,b}(\\sigma)$ is the empirical probability that the virtual agent (all agents but i) report $\\sigma$ on task $b$. $\\hat{x}_{i,b}$ is the report of agent i on task b. More importantly, $K = \\partial f(JP)$ is a scoring function that depends on the input function $f$. Furthermore, $f^*$ is the convex conjugate of function $f$.\n",
    "\n",
    "   1) TVD: $f(a) = \\frac{1}{2}|a - 1|$; $\\quad f^*(b) = b$ if $|b| <= 1/2$, otherwise $f^*(b) = \\infty$; $\\quad\\partial f(a) = \\frac{1}{2}$ if $a > 1$, $-\\frac{1}{2}$ if $a < 1$, $[-\\frac{1}{2},\\frac{1}{2}]$ if $a = 1$.\n",
    "   \n",
    "   2) KL:   $f(a) = a\\log a$; $\\quad f^*(b) = \\exp(b-1)$; $\\quad \\partial f(a) = 1 + \\log (a)$.\n",
    "   \n",
    "   3) Sqr:   $f(a) = (a-1)^2$; $quad f^*(b) = 1 + \\frac{1}{4}b^2$; $\\quad \\partial f(a) = 2a$.\n",
    "   \n",
    "   4) Hlg:   $f(a) = \\left(1-\\sqrt{a}\\right)^2$; $\\qquad f^*(b) = \\frac{b}{1-b}$; $\\quad\\partial f(a) = 1 - \\frac{1}{\\sqrt(a)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mechanism_PMI_individual(X, f, para, i):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"f\" is the index of the convex function for the f-PMI mechanism, f = 0, 1, 2, 3 corresponds to the four f functions that we implement;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "           \"i\" is the index of a particular agent.\n",
    "    Output: \"S\" is the score of agent i computed with the f-PMI mechanism.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    m = para.m\n",
    "    X_ni = np.vstack((X[0:i], X[i+1:n]))\n",
    "    S = PMI_learner(X_ni, X[i], f, para)\n",
    "\n",
    "    return S\n",
    "\n",
    "def PMI_learner(X, Xi, f, para):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is a matrix of agents' reports (all agents but i);\n",
    "           \"Xi\" is a vector of agents i's reports;\n",
    "           \"f\" is the index of the convex function;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "    Output: \"S\" is the score of agent i computed with the f-PMI mechanism.\n",
    "    \"\"\"\n",
    "    m = para.m\n",
    "    index_i = np.where(Xi != 0)[0]\n",
    "    T = np.size(np.where(Xi != 0)[0])*3\n",
    "    m_i = len(index_i)\n",
    "    K = para.K\n",
    "    \n",
    "    # Seperating the tasks. We guarantee the tasks that agent i answers are equally divided.\n",
    "    index_i_train, index_i_test = np.array_split(index_i, 2)\n",
    "    index_X_train, index_X_test = np.array_split(np.where(Xi == 0)[0], 2)\n",
    "    index_train = np.union1d(index_X_train, index_i_train)\n",
    "    index_test = np.union1d(index_X_test, index_i_test)\n",
    "    \n",
    "    Xi_int = Xi.copy().astype(int)\n",
    "    pv = soft_predictor_learner(X,para) # learn the report distribution of the virtual agent\n",
    "    Qv = np.average(pv[index_train], axis = 0) # estimate the empirical marginal distribution of the virtual agent\n",
    "    P, Qi = distribution_learner(Xi[index_train], pv[index_train], para) # estimate the empirical joint and marginal distribution\n",
    "    \n",
    "    S = 0\n",
    "    for j in range(T): # repeat T times and randomly sample the bonus/penalty tasks\n",
    "        b,q = sample(list(index_i_test), 2)\n",
    "        p = sample(list(index_test), 1)[0]\n",
    "        while p == b or p == q:\n",
    "            p = sample(list(index_test),1)[0]\n",
    "\n",
    "        Mi = MI_computer_PMI(Qi, Qv, P, pv, b, p, q, Xi_int, f)\n",
    "        S += Mi\n",
    "    S = S/(T)\n",
    "\n",
    "    return S\n",
    "\n",
    "def MI_computer_PMI(Qi, Qv, P, pv, b, p, q, Xi, f):\n",
    "    \"\"\"\n",
    "    Input: \"Qi\" is the marginal distribution of an agent i;\n",
    "           \"Qv\" is the marginal distribution of the virtual agent, i.e. the empirical marginal distribution of all agents' report but i;\n",
    "           \"P\" is the joint distribution between agent i and the virtual agent;\n",
    "           \"pv\" is the report distribution of the virtual agent on each task;\n",
    "           \"b\" is the index of the bonus task;\n",
    "           \"p\" and \"q\" are the index of the penalty tasks;\n",
    "           \"Xi\" is agent i's reports;\n",
    "           \"f\" is the index of the convex function.\n",
    "    Output: \"Mi\" is estimated mutual information between agent i and the virtual agent.\n",
    "    \"\"\"\n",
    "    K = len(Qi) # The size of the signal space\n",
    "    Mi = 0\n",
    "    K_b = 0 # The value of the scoring function K given the bonus task\n",
    "    K_p = 0 # The value of the scoring function K given the penalty tasks\n",
    "    predict_b = pv[b] # The prediction of the learned soft predictor on task b\n",
    "    predict_p = pv[p] \n",
    "    \n",
    "    # Compute the score on the bonus task\n",
    "    product_marginal = np.outer(Qi, Qv)\n",
    "    if Qi[Xi[b]-1] != 0: \n",
    "        Jp_b = P[Xi[b]-1]/product_marginal[Xi[b]-1] # The value of the joint to marginal product ratio given bonus task\n",
    "        K_b_dist = np.zeros(K)\n",
    "        if f == 0:\n",
    "            K_b_dist[np.where(Jp_b > 1)[0]] = 0.5\n",
    "            K_b_dist[np.where(Jp_b < 1)[0]] = -0.5\n",
    "        elif f == 1:\n",
    "            K_JP = 1 + np.log(Jp_b)\n",
    "            K_b_dist = K_JP.copy()\n",
    "            K_b_dist[np.where(K_JP > 10)[0]] = 10 # To avoid outliers, we truncate JP at +- 10\n",
    "            K_b_dist[np.where(K_JP < -10)[0]] = -10\n",
    "        elif f == 2:\n",
    "            K_b_dist = 2*(Jp_b - 1)\n",
    "        elif f == 3:\n",
    "            K_JP = 1 - 1/np.sqrt(Jp_b)\n",
    "            K_b_dist = K_JP.copy()\n",
    "            K_b_dist[np.where(K_JP < -10)[0]] = -10\n",
    "        K_b = np.sum(pv[b]*K_b_dist)\n",
    "        \n",
    "    # Compute the score on the penalty tasks and get the estimated mutual information\n",
    "    if Qi[Xi[q]-1] != 0:\n",
    "        Jp_p = P[Xi[q]-1]/product_marginal[Xi[q]-1] # The value of the joint to marginal product ratio given a penalty task\n",
    "        K_p_dist = np.zeros(K)\n",
    "        if f == 0:\n",
    "            K_p_dist[np.where(Jp_p > 1)[0]] = 0.5\n",
    "            K_p_dist[np.where(Jp_p < 1)[0]] = -0.5\n",
    "            K_p = np.sum(pv[p]*K_p_dist)\n",
    "            Mi = K_b - K_p\n",
    "            \n",
    "        elif f == 1:\n",
    "            K_JP = 1 + np.log(Jp_p)\n",
    "            K_p_dist = K_JP.copy()\n",
    "            K_p_dist[np.where(K_JP > 10)[0]] = 10 # To avoid outliers, we truncate JP at +- 10\n",
    "            K_p_dist[np.where(K_JP < -10)[0]] = -10\n",
    "            K_p = np.sum(pv[p]*K_p_dist)\n",
    "            Mi = K_b - np.exp(K_p-1)\n",
    "            \n",
    "        elif f == 2:\n",
    "            K_p_dist = 2*(Jp_p - 1)\n",
    "            K_p = np.sum(pv[p]*K_p_dist)\n",
    "            Mi = K_b - np.square(K_p)/4 - K_p\n",
    "            \n",
    "        elif f == 3:\n",
    "            K_JP = 1 - 1/np.sqrt(Jp_p)\n",
    "            K_p_dist = K_JP.copy()\n",
    "            K_p_dist[np.where(K_JP < -10)[0]] = -10\n",
    "            K_p = np.sum(pv[p]*K_p_dist)\n",
    "            Mi = K_b - K_p/(1-K_p)\n",
    "    \n",
    "    return Mi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 The determinant mutual information mechanim (DMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the goal is to reward each agent based on the estimated mutual information between agents' reports. \n",
    "Determinant mutual information is a generalized version of Shannon mutual information. Specifically, for a pair of agents $i$ and $j$, the set of the commonly answered tasks is divided into two disjoint subsets $A$ and $B$. Again, we empirically estimate the joint distribution with reports in $A$ and $B$ respectively, and score agent $i$ the product of the determinants of these two estimated joint distribution matrices and take average over all the other agents. Again, we implement the trick of the virtual agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mechanism_DMI_individual(X, para, i):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is all agents' report matrix;\n",
    "           \"para\" contains the crowdsourcing parameters;\n",
    "           \"i\" is the index of a particular agent.\n",
    "    Output: \"S\" is the score of agent i computed with the DMI mechanism.\n",
    "    \"\"\"\n",
    "    n = np.size(X, axis = 0)\n",
    "    mi = para.mi\n",
    "    X_ni = np.vstack((X[0:i], X[i+1:n]))\n",
    "    pv = soft_predictor_learner(X_ni, para) # report distribution of the virtual agent (the empirical report distribution of all agents but i)\n",
    "    \n",
    "    # Separate agent i's reports into two sets. Because the tasks are randomly sampled, we simply separate based on the first half and the second half.\n",
    "    Xi_A = X[i].copy()\n",
    "    Xi_A[np.where(X[i] != 0)[0][0:int(mi/2)]] = 0\n",
    "    Xi_B = X[i].copy()\n",
    "    Xi_B[np.where(X[i] != 0)[0][int(mi/2):mi]] = 0\n",
    "\n",
    "    # Learn the joint distribution with reports in A and B respectively.\n",
    "    PA,_ = distribution_learner(Xi_A, pv, para)\n",
    "    PB,_ = distribution_learner(Xi_B, pv, para)\n",
    "\n",
    "    S = np.linalg.det(PA)*np.linalg.det(PB)\n",
    "    return S\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Running the Performance Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part will run the performance measurements to generate samples of the performance scores under different settings. In particular, 3.1 will let one agent deviate to a slightly higher effort so as to learn the equilibrium effort; 3.2 will let one agent deviate to an untruthful strategy so as to test the truthfulness robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Effort Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Spot-checking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running spot-checking mechanisms in W1\n",
    "---------------------------------\n",
    "There are 2 types of spot-checking mechanisms and 1 parameter (\"check_prob\") to control the checking probability.\n",
    "One can switch between these two mechanisms by comment/uncomment one at a time.\n",
    "\"\"\"\n",
    "w_1 = np.array([0.612903, 0.387097])\n",
    "Gamma_w1 = np.array([[0.6842, 0.2211, 0.0316, 0.0368, 0.0263], [0.0917, 0.1916, 0.05, 0.2, 0.4667]])\n",
    "Gamma_random = np.ones((2,5))/5\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52 # Given m = 1000, mi = 100, n0 = 5, n should be at least 50. We provide to extra agents in favor of the random assignment process.\n",
    "T = 100 # In total, each setting will be run T times and generate n*T = 5200 samples of performance scores.\n",
    "Effort_list = np.arange(0,1,0.02) # The list of xi\n",
    "S_samples = np.zeros((len(Effort_list),n*T))\n",
    "check_prob = 0.2 # Probability of spot-checking\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print(xi)\n",
    "    for t in range(T):\n",
    "        para_w = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para_w, [xi], [n])\n",
    "        Y_check = np.array(Y.copy())\n",
    "        index = spot_check_random(X, check_prob)\n",
    "        index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "        Y_check[index_cover] = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_acc_w1(X,Y_check)\n",
    "#         S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_DG_w1(X,Y_check)\n",
    "\n",
    "\"\"\"\n",
    "Save the samples as .npy directly.\n",
    "\"\"\"\n",
    "np.save('Samples/Effort_equilibrium/W1/Spot_check_Acc/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W1/Spot_check_DG/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running spot-checking mechanisms in W2\n",
    "---------------------------------\n",
    "There are 2 types of spot-checking mechanisms and 1 parameter (\"check_prob\") to control the checking probability.\n",
    "One can switch between these two mechanisms by comment/uncomment one at a time.\n",
    "\"\"\"\n",
    "w_w2 = np.array([0.19587629, 0.24054983, 0.24742268, 0.3161512])\n",
    "Gamma_w2 = np.array([[0.77056673, 0.12157221, 0.08409506, 0.023766],\n",
    "                 [0.09083969, 0.7351145, 0.12977099, 0.04427481],\n",
    "                 [0.03326256, 0.06157113, 0.86624204, 0.03892427],\n",
    "                 [0.06785509, 0.16388729, 0.09890742, 0.6693502]])\n",
    "Gamma_random = np.ones((4,4))/4\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52 # Given m = 1000, mi = 100, n0 = 5, n should be at least 50. We provide to extra agents in favor of the random assignment process.\n",
    "T = 100 # In total, each setting will be run T times and generate n*T = 5200 samples of performance scores.\n",
    "Effort_list = np.arange(0,1,0.02) # The list of xi\n",
    "S_samples = np.zeros((len(Effort_list),n*T))\n",
    "check_prob = 0.2 # Probability of spot-checking\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print(xi)\n",
    "    for t in range(T):\n",
    "        para_w = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal=[1,2,3,4])\n",
    "        X, Y, agent_e = Report_Generator(para_w, [xi], [n])\n",
    "        Y_check = np.array(Y.copy())\n",
    "        index = spot_check_random(X, check_prob)\n",
    "        index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "        Y_check[index_cover] = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_acc_w2(X,Y_check)\n",
    "#         S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_DG_w2(X,Y_check)\n",
    "\n",
    "\"\"\"\n",
    "Save the samples as .npy directly.\n",
    "\"\"\"\n",
    "np.save('Samples/Effort_equilibrium/W2/Spot_check_Acc/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W2/Spot_check_DG/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Peer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before deviation:  0.0 2022-08-14 00:36:30.484143\n",
      "before deviation:  0.02 2022-08-14 00:42:20.763561\n",
      "before deviation:  0.04 2022-08-14 00:48:10.191113\n",
      "before deviation:  0.06 2022-08-14 00:53:59.731219\n",
      "before deviation:  0.08 2022-08-14 00:59:49.095095\n",
      "before deviation:  0.1 2022-08-14 01:05:38.829530\n",
      "before deviation:  0.12 2022-08-14 01:11:28.002807\n",
      "before deviation:  0.14 2022-08-14 01:17:17.528471\n",
      "before deviation:  0.16 2022-08-14 01:23:06.983325\n",
      "before deviation:  0.18 2022-08-14 01:28:56.652280\n",
      "before deviation:  0.2 2022-08-14 01:34:46.271650\n",
      "before deviation:  0.22 2022-08-14 01:40:35.893099\n",
      "before deviation:  0.24 2022-08-14 01:46:25.373251\n",
      "before deviation:  0.26 2022-08-14 01:52:14.748524\n",
      "before deviation:  0.28 2022-08-14 01:58:04.264439\n",
      "before deviation:  0.3 2022-08-14 02:03:53.707577\n",
      "before deviation:  0.32 2022-08-14 02:09:42.921785\n",
      "before deviation:  0.34 2022-08-14 02:15:32.446102\n",
      "before deviation:  0.36 2022-08-14 02:21:21.520887\n",
      "before deviation:  0.38 2022-08-14 02:27:10.753585\n",
      "before deviation:  0.4 2022-08-14 02:33:00.438771\n",
      "before deviation:  0.42 2022-08-14 02:38:50.133311\n",
      "before deviation:  0.44 2022-08-14 02:44:39.374188\n",
      "before deviation:  0.46 2022-08-14 02:50:29.068558\n",
      "before deviation:  0.48 2022-08-14 02:56:18.658697\n",
      "before deviation:  0.5 2022-08-14 03:01:56.820954\n",
      "before deviation:  0.52 2022-08-14 03:07:35.011458\n",
      "before deviation:  0.54 2022-08-14 03:13:12.966953\n",
      "before deviation:  0.56 2022-08-14 03:18:50.838873\n",
      "before deviation:  0.58 2022-08-14 03:24:29.117757\n",
      "before deviation:  0.6 2022-08-14 03:30:07.277569\n",
      "before deviation:  0.62 2022-08-14 03:35:45.010113\n",
      "before deviation:  0.64 2022-08-14 03:41:23.038357\n",
      "before deviation:  0.66 2022-08-14 03:47:01.294393\n",
      "before deviation:  0.68 2022-08-14 03:52:39.125131\n",
      "before deviation:  0.7000000000000001 2022-08-14 03:58:17.294989\n",
      "before deviation:  0.72 2022-08-14 04:03:55.339745\n",
      "before deviation:  0.74 2022-08-14 04:09:33.686140\n",
      "before deviation:  0.76 2022-08-14 04:15:11.435748\n",
      "before deviation:  0.78 2022-08-14 04:20:49.942074\n",
      "before deviation:  0.8 2022-08-14 04:26:27.733945\n",
      "before deviation:  0.8200000000000001 2022-08-14 04:32:05.505233\n",
      "before deviation:  0.84 2022-08-14 04:37:43.647323\n",
      "before deviation:  0.86 2022-08-14 04:43:21.875984\n",
      "before deviation:  0.88 2022-08-14 04:48:59.975891\n",
      "before deviation:  0.9 2022-08-14 04:54:37.844369\n",
      "before deviation:  0.92 2022-08-14 05:00:15.897576\n",
      "before deviation:  0.9400000000000001 2022-08-14 05:05:53.793493\n",
      "before deviation:  0.96 2022-08-14 05:11:31.647865\n",
      "after deviation:  0.0 2022-08-14 05:17:09.537190\n",
      "after deviation:  0.02 2022-08-14 05:22:46.448669\n",
      "after deviation:  0.04 2022-08-14 05:28:23.554279\n",
      "after deviation:  0.06 2022-08-14 05:34:00.666503\n",
      "after deviation:  0.08 2022-08-14 05:39:37.821098\n",
      "after deviation:  0.1 2022-08-14 05:45:15.049171\n",
      "after deviation:  0.12 2022-08-14 05:50:51.990963\n",
      "after deviation:  0.14 2022-08-14 05:56:29.139770\n",
      "after deviation:  0.16 2022-08-14 06:02:06.516581\n",
      "after deviation:  0.18 2022-08-14 06:07:43.804663\n",
      "after deviation:  0.2 2022-08-14 06:13:21.067774\n",
      "after deviation:  0.22 2022-08-14 06:18:58.919674\n",
      "after deviation:  0.24 2022-08-14 06:24:36.139763\n",
      "after deviation:  0.26 2022-08-14 06:30:13.704489\n",
      "after deviation:  0.28 2022-08-14 06:35:50.062931\n",
      "after deviation:  0.3 2022-08-14 06:41:27.823525\n",
      "after deviation:  0.32 2022-08-14 06:47:05.645353\n",
      "after deviation:  0.34 2022-08-14 06:52:44.007968\n",
      "after deviation:  0.36 2022-08-14 06:58:22.080882\n",
      "after deviation:  0.38 2022-08-14 07:04:00.441517\n",
      "after deviation:  0.4 2022-08-14 07:09:38.714012\n",
      "after deviation:  0.42 2022-08-14 07:15:16.475387\n",
      "after deviation:  0.44 2022-08-14 07:20:54.579042\n",
      "after deviation:  0.46 2022-08-14 07:26:32.794868\n",
      "after deviation:  0.48 2022-08-14 07:32:10.751027\n",
      "after deviation:  0.5 2022-08-14 07:37:49.131745\n",
      "after deviation:  0.52 2022-08-14 07:43:27.148226\n",
      "after deviation:  0.54 2022-08-14 07:48:59.684169\n",
      "after deviation:  0.56 2022-08-14 07:54:29.640650\n",
      "after deviation:  0.58 2022-08-14 07:59:58.639360\n",
      "after deviation:  0.6 2022-08-14 08:05:27.823441\n",
      "after deviation:  0.62 2022-08-14 08:10:56.049393\n",
      "after deviation:  0.64 2022-08-14 08:16:24.655219\n",
      "after deviation:  0.66 2022-08-14 08:21:53.909919\n",
      "after deviation:  0.68 2022-08-14 08:27:22.389093\n",
      "after deviation:  0.7000000000000001 2022-08-14 08:32:51.288117\n",
      "after deviation:  0.72 2022-08-14 08:38:20.163694\n",
      "after deviation:  0.74 2022-08-14 08:43:48.300597\n",
      "after deviation:  0.76 2022-08-14 08:49:16.541191\n",
      "after deviation:  0.78 2022-08-14 08:54:45.200192\n",
      "after deviation:  0.8 2022-08-14 09:00:14.246549\n",
      "after deviation:  0.8200000000000001 2022-08-14 09:05:42.844883\n",
      "after deviation:  0.84 2022-08-14 09:11:11.344508\n",
      "after deviation:  0.86 2022-08-14 09:16:40.277547\n",
      "after deviation:  0.88 2022-08-14 09:22:09.283499\n",
      "after deviation:  0.9 2022-08-14 09:27:38.107674\n",
      "after deviation:  0.92 2022-08-14 09:33:07.219897\n",
      "after deviation:  0.9400000000000001 2022-08-14 09:38:35.594536\n",
      "after deviation:  0.96 2022-08-14 09:44:04.066125\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running peer prediction mechanisms in W1\n",
    "---------------------------------\n",
    "There are 5 types of peer prediction mechanisms and 2 of them have additional 4 types of f functions.\n",
    "Totally, there are 11 mechanisms. \n",
    "To run all of them, simply change \"f\" while running \"mechanism_matrix_individual()\" and \"mechanism_pairing_individual()\"\n",
    "and one can switch to different mechanisms by comment/uncomment one mechanism at a time.\n",
    "\"\"\"\n",
    "w_w1 = np.array([0.612903, 0.387097])\n",
    "Gamma_w1 = np.array([[0.6842, 0.2211, 0.0316, 0.0368, 0.0263], [0.0917, 0.1916, 0.05, 0.2, 0.4667]])\n",
    "Gamma_random = np.ones((2,5))/5\n",
    "\n",
    "\"\"\"\n",
    "Switch the f functions\n",
    "\"\"\"\n",
    "f = 0 \n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52 # Given m = 1000, mi = 100, n0 = 5, n should be at least 50. We provide to extra agents in favor of the random assignment process.\n",
    "T = 100 # In total, each setting will be run n*T times and generate 5200 samples of performance scores.\n",
    "Effort_list = np.arange(0,0.97,0.02) # The list of xi\n",
    "S_samples = np.zeros((2,len(Effort_list),n*T)) # The first dimension is before/after an unilateral deviation; the second dimention is the equilibrium effort xi; the third dimension is the samples.\n",
    "Mechanisms = ['tvd','kl','sqr','hlg'] # Four f functions\n",
    "\n",
    "\"\"\"\n",
    "First, generate samples when everyone exerts effort xi\n",
    "------------------------\n",
    "Because for peer prediction, the score distribution after a unilateral deviation is not equal to the score distribution\n",
    "where everyone deviates to a higher effort, we have to generate the scores separately. \n",
    "\"\"\"\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print('before deviation: ', xi, datetime.datetime.now())\n",
    "    for t in range(n*T):\n",
    "        para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "        i = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[0,j,t] = mechanism_MMI_individual(X, f, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_PMI_individual(X, f, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_DMI_individual(X, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_OA_individual(X, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_PTS_individual(X, para, i)\n",
    "\n",
    "\"\"\"\n",
    "Then, generate samples when one agent deviates to effort xi+de\n",
    "\"\"\"\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print('after deviation: ', xi, datetime.datetime.now())\n",
    "    for t in range(n*T):\n",
    "        para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi+0.04], [n-1,1])\n",
    "        i = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[1,j,t] = mechanism_MMI_individual(X, f, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_PMI_individual(X, f, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_DMI_individual(X, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_OA_individual(X, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_PTS_individual(X, para, i)\n",
    "       \n",
    "\"\"\"\n",
    "Save the samples as .npy directly.\n",
    "\"\"\"\n",
    "np.save('Samples/Effort_equilibrium/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mechanism_'+Mechanisms[f]+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W1/Peer_prediction_PMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mechanism_'+Mechanisms[f]+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W1/Peer_prediction_DMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W1/Peer_prediction_OA/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Effort_equilibrium/W1/Peer_prediction_PTS/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_samples.npy', S_samples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Running peer prediction mechanisms in W2\n",
    "\"\"\"\n",
    "import datetime\n",
    "w_w2 = np.array([0.19587629, 0.24054983, 0.24742268, 0.3161512])\n",
    "Gamma_w2 = np.array([[0.77056673, 0.12157221, 0.08409506, 0.023766],\n",
    "                 [0.09083969, 0.7351145, 0.12977099, 0.04427481],\n",
    "                 [0.03326256, 0.06157113, 0.86624204, 0.03892427],\n",
    "                 [0.06785509, 0.16388729, 0.09890742, 0.6693502]])\n",
    "Gamma_random = np.ones((4,4))/4\n",
    "\n",
    "\"\"\"\n",
    "Switch the f functions\n",
    "\"\"\"\n",
    "f = 0 \n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 100\n",
    "Effort_list = np.arange(0,0.95,0.02)\n",
    "S_samples = np.zeros((2,len(Effort_list),n*T))\n",
    "Mechanisms = ['tvd','kl','sqr','hlg']\n",
    "\n",
    "\"\"\"\n",
    "First, generate samples when everyone exerts effort xi\n",
    "\"\"\"\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print('before deviation: ', xi, datetime.datetime.now())\n",
    "    for t in range(n*T):\n",
    "        para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal = [1,2,3,4])\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "        i = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[0,j,t] = mechanism_MMI_individual(X, f, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_PMI_individual(X, f, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_DMI_individual(X, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_OA_individual(X, para, i)\n",
    "#         S_samples[0,j,t] = mechanism_PTS_individual(X, para, i)\n",
    "\n",
    "\"\"\"\n",
    "Then, generate samples when one agent deviates to effort xi+de\n",
    "\"\"\"\n",
    "for j,xi in enumerate(Effort_list):\n",
    "    print('after deviation: ', xi, datetime.datetime.now())\n",
    "    for t in range(n*T):\n",
    "        para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal = [1,2,3,4])\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi+0.04], [n-1,1])\n",
    "        i = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[1,j,t] = mechanism_MMI_individual(X, f, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_PMI_individual(X, f, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_DMI_individual(X, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_OA_individual(X, para, i)\n",
    "#         S_samples[1,j,t] = mechanism_PTS_individual(X, para, i)\n",
    "\n",
    "# To save space, we only store the mean and the std. Rename for different mechanisms\n",
    "mean = np.average(S_samples[0], axis = 1)\n",
    "mean_deviate = np.average(S_samples[1], axis = 1)\n",
    "variance = np.std(S_samples[0], axis = 1)\n",
    "variance_deviate = np.std(S_samples[1], axis = 1)\n",
    "np.save('Samples/Effort_equilibrium/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean.npy', mean)\n",
    "np.save('Samples/Effort_equilibrium/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean_deviate.npy', mean_deviate)\n",
    "np.save('Samples/Effort_equilibrium/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance.npy', variance)\n",
    "np.save('Samples/Effort_equilibrium/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance_deviate.npy', variance_deviate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Report Strategy Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Untruthful strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Several examples of the heuristically chosen untruthful strategies. One can easily add more.\n",
    "\"\"\"\n",
    "\n",
    "def strategy_mixed_w1(X, s, mixed_prob):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is a matrix of agents' reports (all agents but i);\n",
    "           \"s\" is the index of the untruthful strategy;\n",
    "           \"mixed_prob\" is the probability of playing the untruthful strategy.\n",
    "    Output: \"X_hat\" is report matrix after deviation.\n",
    "    \"\"\"\n",
    "    X_hat = X.copy()\n",
    "    index = np.where(X_hat != 0)[0]\n",
    "    index = np.random.choice(index, size=int(len(index)*mixed_prob), replace=False)\n",
    "    if s == 0:\n",
    "        X_hat[index[np.where(X[index] == 1)[0]]] = 2\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 3\n",
    "        X_hat[index[np.where(X[index] == 3)[0]]] = 4\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 5\n",
    "    if s == 1:\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 5\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 1\n",
    "    if s == 2: \n",
    "        X_hat[index[np.where(X[index] == 3)[0]]] = 4\n",
    "    if s == 3:\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 2\n",
    "    if s == 4:\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 3\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 3\n",
    "    if s == 5:\n",
    "        X_hat[index[np.where(X[index] == 5)[0]]] = 4\n",
    "    if s == 6:\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 1\n",
    "    return X_hat\n",
    "\n",
    "def strategy_mixed_w2(X, s, mixed_prob):\n",
    "    \"\"\"\n",
    "    Input: \"X\" is a matrix of agents' reports (all agents but i);\n",
    "           \"s\" is the index of the untruthful strategy;\n",
    "           \"mixed_prob\" is the probability of playing the untruthful strategy.\n",
    "    Output: \"X_hat\" is report matrix after deviation.\n",
    "    \"\"\"\n",
    "    X_hat = X.copy()\n",
    "    index = np.where(X_hat != 0)[0]\n",
    "    index = np.random.choice(index, size=int(len(index)*mixed_prob), replace=False) # randomly choose a subset to misreport\n",
    "    if s == 0:\n",
    "        X_hat[index[np.where(X[index] == 1)[0]]] = 2\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 3\n",
    "        X_hat[index[np.where(X[index] == 3)[0]]] = 4\n",
    "    if s == 1:\n",
    "        X_hat[index[np.where(X[index] == 1)[0]]] = 4\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 3\n",
    "    if s == 2: \n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 3\n",
    "        X_hat[index[np.where(X[index] == 2)[0]]] = 1\n",
    "    if s == 3:\n",
    "        X_hat[index[np.where(X[index] == 3)[0]]] = 2\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 1\n",
    "    if s == 4:\n",
    "        X_hat[index[np.where(X[index] == 4)[0]]] = 2\n",
    "        X_hat[index[np.where(X[index] == 1)[0]]] = 3\n",
    "    if s == 5:\n",
    "        X_hat[index[np.where(X[index] == 1)[0]]] = 2\n",
    "    if s == 6:\n",
    "        X_hat[index[np.where(X[index] == 3)[0]]] = 4\n",
    "    return X_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Spot-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Truthfulness robustness W1\n",
    "\"\"\"\n",
    "\n",
    "w_w1 = np.array([0.612903, 0.387097])\n",
    "Gamma_w1 = np.array([[0.6842, 0.2211, 0.0316, 0.0368, 0.0263], [0.0917, 0.1916, 0.05, 0.2, 0.4667]])\n",
    "Gamma_random = np.ones((2,5))/5\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 100\n",
    "check_prob = 0.2 # probability of spot-checking\n",
    "mixed_prob = 0.5 # probability of mixed reporting\n",
    "Effort_list = [0.1, 0.4, 0.7, 1] # all agents' effort \n",
    "S_samples = np.zeros((4,n*T)) # Store the score samples before deviation. The first dimension is the effort level, the second dimension stores the samepls.\n",
    "S_samples_deviate = np.zeros((4,5,n*T)) # Store the score samples after deviation. The first dimension is the effort level, the second dimension is the strategies, and the third dimension stores the samepls.\n",
    "\n",
    "\"\"\"\n",
    "Before deviation\n",
    "\"\"\"\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for t in range(T):\n",
    "        para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para, [xi], [n])\n",
    "        Y_check = np.array(Y.copy())\n",
    "        index = spot_check_greedy(X, check_prob)\n",
    "        index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "        Y_check[index_cover] = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_acc_w1(X,Y_check)\n",
    "#         S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_DG_w1(X,Y_check)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After deviation\n",
    "\"\"\"\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for s in range(5): # the number of tested untruthful strategies\n",
    "        for t in range(T):\n",
    "            para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "            X, Y, agent_e = Report_Generator(para, [xi], [n])\n",
    "            Y_check = np.array(Y.copy())\n",
    "            index = spot_check_greedy(X, check_prob)\n",
    "            index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "            Y_check[index_cover] = 0\n",
    "            for i in range(n):\n",
    "                X[i] = strategy_mixed_w1(X[i], s, mixed_prob)\n",
    "                \n",
    "            \"\"\"\n",
    "            Switch the mechanisms\n",
    "            \"\"\"\n",
    "            S_samples_deviate[j,s,n*t:n*(t+1)] = Spot_check_mechanism_acc_w1(X,Y_check)\n",
    "#             S_samples_deviate[j,s,n*t:n*(t+1)] = Spot_check_mechanism_DG_w1(X,Y_check)\n",
    "    print('after', xi)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "\"\"\"\n",
    "Save the samples\n",
    "\"\"\"\n",
    "np.save('Samples/Truthfulness_robustness/W1/Spot_checking_Acc/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Spot_checking_Acc/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples_deviate.npy', S_samples_deviate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Truthfulness robustness W2\n",
    "\"\"\"\n",
    "\n",
    "w_w2 = np.array([0.19587629, 0.24054983, 0.24742268, 0.3161512])\n",
    "Gamma_w2 = np.array([[0.77056673, 0.12157221, 0.08409506, 0.023766],\n",
    "                 [0.09083969, 0.7351145, 0.12977099, 0.04427481],\n",
    "                 [0.03326256, 0.06157113, 0.86624204, 0.03892427],\n",
    "                 [0.06785509, 0.16388729, 0.09890742, 0.6693502]])\n",
    "Gamma_random = np.ones((4,4))/4\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 100\n",
    "check_prob = 0.2 # probability of spot-checking\n",
    "mixed_prob = 0.5 # probability of mixed reporting\n",
    "Effort_list = [0.1, 0.4, 0.7, 1] # all agents' effort \n",
    "S_samples = np.zeros((4,n*T)) # Store the score samples before deviation. The first dimension is the effort level, the second dimension stores the samepls.\n",
    "S_samples_deviate = np.zeros((4,5,n*T)) # Store the score samples after deviation. The first dimension is the effort level, the second dimension is the strategies, and the third dimension stores the samepls.\n",
    "\n",
    "\"\"\"\n",
    "Before deviation\n",
    "\"\"\"\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for t in range(T):\n",
    "        para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal=[1,2,3,4])\n",
    "        X, Y, agent_e = Report_Generator(para, [xi], [n])\n",
    "        Y_check = np.array(Y.copy())\n",
    "        index = spot_check_greedy(X, check_prob)\n",
    "        index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "        Y_check[index_cover] = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_acc_w2(X,Y_check)\n",
    "#         S_samples[j,n*t:n*(t+1)] = Spot_check_mechanism_DG_w2(X,Y_check)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "After deviation\n",
    "\"\"\"\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for s in range(5): # the number of tested untruthful strategies\n",
    "        for t in range(T):\n",
    "            para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal=[1,2,3,4])\n",
    "            X, Y, agent_e = Report_Generator(para, [xi], [n])\n",
    "            Y_check = np.array(Y.copy())\n",
    "            index = spot_check_greedy(X, check_prob)\n",
    "            index_cover = np.setdiff1d(np.array(range(m)), index)\n",
    "            Y_check[index_cover] = 0\n",
    "            for i in range(n):\n",
    "                X[i] = strategy_mixed_w2(X[i], s, mixed_prob)\n",
    "                \n",
    "            \"\"\"\n",
    "            Switch the mechanisms\n",
    "            \"\"\"\n",
    "            S_samples_deviate[j,s,n*t:n*(t+1)] = Spot_check_mechanism_acc_w2(X,Y_check)\n",
    "#             S_samples_deviate[j,s,n*t:n*(t+1)] = Spot_check_mechanism_DG_w2(X,Y_check)\n",
    "    print('after', xi)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "\"\"\"\n",
    "Save the samples\n",
    "\"\"\"\n",
    "np.save('Samples/Truthfulness_robustness/W2/Spot_checking_Acc/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "np.save('Samples/Truthfulness_robustness/W2/Spot_checking_Acc/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples_deviate.npy', S_samples_deviate)\n",
    "# np.save('Samples/Truthfulness_robustness/W2/Spot_checking_DG/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples.npy', S_samples)\n",
    "# np.save('Samples/Truthfulness_robustness/W2/Spot_checking_DG/strategic_m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_check_p_'+str(check_prob)+'_samples_deviate.npy', S_samples_deviate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Peer prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Truthfulness robustness W1\n",
    "\"\"\"\n",
    "w_w1 = np.array([0.612903, 0.387097])\n",
    "Gamma_w1 = np.array([[0.6842, 0.2211, 0.0316, 0.0368, 0.0263], [0.0917, 0.1916, 0.05, 0.2, 0.4667]])\n",
    "Gamma_random = np.ones((2,5))/5\n",
    "\n",
    "\"\"\"\n",
    "Switching f\n",
    "\"\"\"\n",
    "f = 0\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 3000\n",
    "mixed_prob = 0.5 # probability of mixed reporting\n",
    "Effort_list = [0.1, 0.4, 0.7, 1]\n",
    "S_samples = np.zeros((4,T))\n",
    "S_samples_deviate = np.zeros((4,5,T))\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for t in range(T):\n",
    "        para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "        index = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#         S_samples[j,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "#         S_samples[j,t] = mechanism_DMI_individual(X, para, index)\n",
    "#         S_samples[j,t] = mechanism_OA_individual(X, para, index)\n",
    "#         S_samples[j,t] = mechanism_PTS_individual(X, para, index)\n",
    "\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for s in range(5):\n",
    "        for t in range(T):\n",
    "            para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "            X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "            index = np.where(agent_e==1)[0][0]\n",
    "            X[index] = strategy_mixed_w1(X[index], s, mixed_prob)\n",
    "            \n",
    "            \"\"\"\n",
    "            Switch the mechanisms\n",
    "            \"\"\"\n",
    "            S_samples_deviate[j,s,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_DMI_individual(X, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_OA_individual(X, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PTS_individual(X, para, index)\n",
    "    print('after', xi)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    \n",
    "# To save space, we only store the mean and the std. Rename for different mechanisms\n",
    "mean = np.average(S_samples, axis = 1)\n",
    "mean_deviate = np.average(S_samples_deviate, axis = 2)\n",
    "variance = np.std(S_samples, axis = 1)\n",
    "variance_deviate = np.std(S_samples_deviate, axis = 2)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean.npy', mean)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean_deviate_mixed.npy', mean_deviate)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance.npy', variance)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance_deviate_mixed.npy', variance_deviate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Truthfulness robustness W2\n",
    "\"\"\"\n",
    "w_w2 = np.array([0.19587629, 0.24054983, 0.24742268, 0.3161512])\n",
    "Gamma_w2 = np.array([[0.77056673, 0.12157221, 0.08409506, 0.023766],\n",
    "                 [0.09083969, 0.7351145, 0.12977099, 0.04427481],\n",
    "                 [0.03326256, 0.06157113, 0.86624204, 0.03892427],\n",
    "                 [0.06785509, 0.16388729, 0.09890742, 0.6693502]])\n",
    "Gamma_random = np.ones((4,4))/4\n",
    "\n",
    "\"\"\"\n",
    "Switching f\n",
    "\"\"\"\n",
    "f = 0\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 3000\n",
    "mixed_prob = 0.5 # probability of mixed reporting\n",
    "Effort_list = [0.1, 0.4, 0.7, 1]\n",
    "S_samples = np.zeros((4,T))\n",
    "S_samples_deviate = np.zeros((4,5,T))\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for t in range(T):\n",
    "        para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal=[1,2,3,4])\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "        index = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "        S_samples[j,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#         S_samples[j,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "#         S_samples[j,t] = mechanism_DMI_individual(X, para, index)\n",
    "#         S_samples[j,t] = mechanism_OA_individual(X, para, index)\n",
    "#         S_samples[j,t] = mechanism_PTS_individual(X, para, index)\n",
    "\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for s in range(5):\n",
    "        for t in range(T):\n",
    "            para = Crowdsourcing(w = w_w2, Gamma_w = Gamma_w2, Gamma_s = Gamma_random, signal=[1,2,3,4])\n",
    "            X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "            index = np.where(agent_e==1)[0][0]\n",
    "            X[index] = strategy_mixed_w2(X[index], s, mixed_prob)\n",
    "            \n",
    "            \"\"\"\n",
    "            Switch the mechanisms\n",
    "            \"\"\"\n",
    "            S_samples_deviate[j,s,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_DMI_individual(X, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_OA_individual(X, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PTS_individual(X, para, index)\n",
    "    print('after', xi)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    \n",
    "# To save space, we only store the mean and the std. Rename for different mechanisms\n",
    "mean = np.average(S_samples, axis = 1)\n",
    "mean_deviate = np.average(S_samples_deviate, axis = 2)\n",
    "variance = np.std(S_samples, axis = 1)\n",
    "variance_deviate = np.std(S_samples_deviate, axis = 2)\n",
    "np.save('Samples/Truthfulness_robustness/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean.npy', mean)\n",
    "np.save('Samples/Truthfulness_robustness/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean_deviate_mixed.npy', mean_deviate)\n",
    "np.save('Samples/Truthfulness_robustness/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance.npy', variance)\n",
    "np.save('Samples/Truthfulness_robustness/W2/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_variance_deviate_mixed.npy', variance_deviate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after 0.2\n",
      "2022-08-16 17:39:11.134627\n",
      "after 0.3\n",
      "2022-08-16 17:59:32.394611\n",
      "after 0.4\n",
      "2022-08-16 18:19:54.673390\n",
      "after 0.5\n",
      "2022-08-16 18:40:17.033655\n",
      "after 0.6\n",
      "2022-08-16 19:00:38.698707\n",
      "after 0.7\n",
      "2022-08-16 19:20:59.121688\n",
      "after 0.8\n",
      "2022-08-16 19:41:20.212646\n",
      "after 0.9\n",
      "2022-08-16 20:01:41.443252\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Truthfulness robustness W1, for a larger range of parameters\n",
    "\"\"\"\n",
    "w_w1 = np.array([0.612903, 0.387097])\n",
    "Gamma_w1 = np.array([[0.6842, 0.2211, 0.0316, 0.0368, 0.0263], [0.0917, 0.1916, 0.05, 0.2, 0.4667]])\n",
    "Gamma_random = np.ones((2,5))/5\n",
    "\n",
    "\"\"\"\n",
    "Switching f\n",
    "\"\"\"\n",
    "Mechanisms = ['tvd', 'kl', 'sqr', 'hlg']\n",
    "f = 0\n",
    "\n",
    "m = 1000\n",
    "mi = 100\n",
    "n0 = 5\n",
    "n = 52\n",
    "T = 3000\n",
    "mixed_prob = 0.5 # probability of mixed reporting\n",
    "Effort_list = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9] # all agents' effort \n",
    "S_samples = np.zeros((8,T))\n",
    "S_samples_deviate = np.zeros((8,7,T))\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for t in range(T):\n",
    "        para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "        X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "        index = np.where(agent_e==1)[0][0]\n",
    "        \n",
    "        \"\"\"\n",
    "        Switch the mechanisms\n",
    "        \"\"\"\n",
    "#         S_samples[j,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#         S_samples[j,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "        S_samples[j,t] = mechanism_DMI_individual(X, para, i)\n",
    "#         S_samples[j,t] = mechanism_OA_individual(X, para, i)\n",
    "#         S_samples[j,t] = mechanism_PTS_individual(X, para, i)\n",
    "\n",
    "\n",
    "for j, xi in enumerate(Effort_list):\n",
    "    for s in range(7):\n",
    "        for t in range(T):\n",
    "            para = Crowdsourcing(w = w_w1, Gamma_w = Gamma_w1, Gamma_s = Gamma_random)\n",
    "            X, Y, agent_e = Report_Generator(para, [xi,xi], [n-1,1])\n",
    "            index = np.where(agent_e==1)[0][0]\n",
    "            X[index] = strategy_mixed_w1(X[index], s, mixed_prob)\n",
    "            \n",
    "            \"\"\"\n",
    "            Switch the mechanisms\n",
    "            \"\"\"\n",
    "#             S_samples_deviate[j,s,t] = mechanism_MMI_individual(X, f, para, index)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PMI_individual(X, f, para, index)\n",
    "            S_samples_deviate[j,s,t] = mechanism_DMI_individual(X, para, i)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_OA_individual(X, para, i)\n",
    "#             S_samples_deviate[j,s,t] = mechanism_PTS_individual(X, para, i)\n",
    "    print('after', xi)\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    \n",
    "# To save space, we only store the mean and the std. Rename for different mechanisms\n",
    "mean = np.average(S_samples, axis = 1)\n",
    "mean_deviate = np.average(S_samples_deviate, axis = 2)\n",
    "std = np.std(S_samples, axis = 1)\n",
    "std_deviate = np.std(S_samples_deviate, axis = 2)\n",
    "# np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'mechanism'+Mechanisms[f]+'_mean_larger.npy', mean)\n",
    "# np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'mechanism'+Mechanisms[f]+'_mean_deviate_larger.npy', mean_deviate)\n",
    "# np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'mechanism'+Mechanisms[f]+'_std_larger.npy', std)\n",
    "# np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_MMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'mechanism'+Mechanisms[f]+'_std_deviate_larger.npy', std_deviate)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_DMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean_larger.npy', mean)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_DMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_mean_deviate_larger.npy', mean_deviate)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_DMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_std_larger.npy', std)\n",
    "np.save('Samples/Truthfulness_robustness/W1/Peer_prediction_DMI/m'+str(m)+'_mi'+str(mi)+'_n0'+str(n0)+'_T'+str(T)+'_std_deviate_larger.npy', std_deviate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
